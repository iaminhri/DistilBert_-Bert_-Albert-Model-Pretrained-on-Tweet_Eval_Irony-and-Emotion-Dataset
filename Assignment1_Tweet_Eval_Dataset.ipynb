{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "fb4f837bbaee4dfba487810f76bb9587": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_dc99c95aed7e4b3d88f407504328cb6f",
              "IPY_MODEL_6dc2026a891546cbb8e222e0f53ba124",
              "IPY_MODEL_f4cd8e37eb27410a87709f882bdc0482",
              "IPY_MODEL_35f89cd34cb24a9eb85d593efce1c1e8"
            ],
            "layout": "IPY_MODEL_42225117c7fe471caf642224b7cb2e99"
          }
        },
        "28aa97c3852e4579b5c0c22ee53d3ff6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_37988b4d3ea64558b3d3dca8c2c4985b",
            "placeholder": "​",
            "style": "IPY_MODEL_9498a8ae30fb44cc9070e17ba923d9dc",
            "value": "<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"
          }
        },
        "85f83eb4e83e4d078f0c61bf1266eb28": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "PasswordModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "PasswordModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "PasswordView",
            "continuous_update": true,
            "description": "Token:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_0ac8e17515e44375823671e3f203bb89",
            "placeholder": "​",
            "style": "IPY_MODEL_77a3033ce31e4adeb069eca2ca553633",
            "value": ""
          }
        },
        "8de106ba66184b5c8086e248ea703221": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "CheckboxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "Add token as git credential?",
            "description_tooltip": null,
            "disabled": false,
            "indent": true,
            "layout": "IPY_MODEL_6ce5734ccfc44731908a7fcd2f111e77",
            "style": "IPY_MODEL_60568aef3e8d4c7fac72704af28140cb",
            "value": true
          }
        },
        "b161d51d01b04716a156b06f67a6ed37": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Login",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_5adccc5d72c54cfa8a5902d22b5e778e",
            "style": "IPY_MODEL_96024aaffd8b442cb16525330da274e7",
            "tooltip": ""
          }
        },
        "c5d4bd24d17e451cbfdb2b14f90b365c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_776f11a485a54650b0116fcc99972cdf",
            "placeholder": "​",
            "style": "IPY_MODEL_14052090bea94e96a670bab8bb41c7c3",
            "value": "\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"
          }
        },
        "42225117c7fe471caf642224b7cb2e99": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": "center",
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "flex",
            "flex": null,
            "flex_flow": "column",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "50%"
          }
        },
        "37988b4d3ea64558b3d3dca8c2c4985b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9498a8ae30fb44cc9070e17ba923d9dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0ac8e17515e44375823671e3f203bb89": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "77a3033ce31e4adeb069eca2ca553633": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6ce5734ccfc44731908a7fcd2f111e77": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "60568aef3e8d4c7fac72704af28140cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5adccc5d72c54cfa8a5902d22b5e778e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "96024aaffd8b442cb16525330da274e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "776f11a485a54650b0116fcc99972cdf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "14052090bea94e96a670bab8bb41c7c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "08b674f946ea45b891896aa46cd9beee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d302c3269ce94ebdb1a60072d1997b9f",
            "placeholder": "​",
            "style": "IPY_MODEL_4634e3581c304e1a8806ac28d441715d",
            "value": "Connecting..."
          }
        },
        "d302c3269ce94ebdb1a60072d1997b9f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4634e3581c304e1a8806ac28d441715d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dc99c95aed7e4b3d88f407504328cb6f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_92a81e9e94f2432abebf84fa93eac4ee",
            "placeholder": "​",
            "style": "IPY_MODEL_96dd1fc12a7d4094ba114883280d04b9",
            "value": "Token is valid (permission: write)."
          }
        },
        "6dc2026a891546cbb8e222e0f53ba124": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_93f96faf55c14156b85215e3d50a6996",
            "placeholder": "​",
            "style": "IPY_MODEL_22ec2c38836d46e9bf3c64576f8bd1ac",
            "value": "Your token has been saved in your configured git credential helpers (store)."
          }
        },
        "f4cd8e37eb27410a87709f882bdc0482": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b0b1c4a860bc4cf79ae130fb21c4a490",
            "placeholder": "​",
            "style": "IPY_MODEL_bcace4f7851c4282b364e761057fd3c9",
            "value": "Your token has been saved to /root/.cache/huggingface/token"
          }
        },
        "35f89cd34cb24a9eb85d593efce1c1e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e272f4c62a7e4bbcac1e2c968d829c62",
            "placeholder": "​",
            "style": "IPY_MODEL_e8b5fcd1b1224f728053ec0051cc77dd",
            "value": "Login successful"
          }
        },
        "92a81e9e94f2432abebf84fa93eac4ee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "96dd1fc12a7d4094ba114883280d04b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "93f96faf55c14156b85215e3d50a6996": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "22ec2c38836d46e9bf3c64576f8bd1ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b0b1c4a860bc4cf79ae130fb21c4a490": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bcace4f7851c4282b364e761057fd3c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e272f4c62a7e4bbcac1e2c968d829c62": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e8b5fcd1b1224f728053ec0051cc77dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import notebook_login\n",
        "notebook_login()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145,
          "referenced_widgets": [
            "fb4f837bbaee4dfba487810f76bb9587",
            "28aa97c3852e4579b5c0c22ee53d3ff6",
            "85f83eb4e83e4d078f0c61bf1266eb28",
            "8de106ba66184b5c8086e248ea703221",
            "b161d51d01b04716a156b06f67a6ed37",
            "c5d4bd24d17e451cbfdb2b14f90b365c",
            "42225117c7fe471caf642224b7cb2e99",
            "37988b4d3ea64558b3d3dca8c2c4985b",
            "9498a8ae30fb44cc9070e17ba923d9dc",
            "0ac8e17515e44375823671e3f203bb89",
            "77a3033ce31e4adeb069eca2ca553633",
            "6ce5734ccfc44731908a7fcd2f111e77",
            "60568aef3e8d4c7fac72704af28140cb",
            "5adccc5d72c54cfa8a5902d22b5e778e",
            "96024aaffd8b442cb16525330da274e7",
            "776f11a485a54650b0116fcc99972cdf",
            "14052090bea94e96a670bab8bb41c7c3",
            "08b674f946ea45b891896aa46cd9beee",
            "d302c3269ce94ebdb1a60072d1997b9f",
            "4634e3581c304e1a8806ac28d441715d",
            "dc99c95aed7e4b3d88f407504328cb6f",
            "6dc2026a891546cbb8e222e0f53ba124",
            "f4cd8e37eb27410a87709f882bdc0482",
            "35f89cd34cb24a9eb85d593efce1c1e8",
            "92a81e9e94f2432abebf84fa93eac4ee",
            "96dd1fc12a7d4094ba114883280d04b9",
            "93f96faf55c14156b85215e3d50a6996",
            "22ec2c38836d46e9bf3c64576f8bd1ac",
            "b0b1c4a860bc4cf79ae130fb21c4a490",
            "bcace4f7851c4282b364e761057fd3c9",
            "e272f4c62a7e4bbcac1e2c968d829c62",
            "e8b5fcd1b1224f728053ec0051cc77dd"
          ]
        },
        "id": "_ZniVO1lDRKk",
        "outputId": "fb56af12-c0d5-48fd-ae32-e94cfa1d59a9"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fb4f837bbaee4dfba487810f76bb9587"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt install git-lfs"
      ],
      "metadata": {
        "id": "Hbzx5sXMDolB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# installing libaries\n",
        "!pip install -U accelerate\n",
        "!pip install -U transformers"
      ],
      "metadata": {
        "id": "ppPazO0LKATE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# importing datasets and tokenizer.\n",
        "!pip install datasets\n",
        "from datasets import load_dataset\n",
        "from transformers import DistilBertTokenizer\n",
        "\n",
        "# loading dataset\n",
        "tweet_dataset = load_dataset('tweet_eval', 'irony')\n",
        "# loading pre-trained model distilbert\n",
        "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
        "\n",
        "# Tokenize function takes a dataset as input, pads it based on max_length and truncates if above max_length.\n",
        "def tokenize_function(example):\n",
        "  return tokenizer(example[\"text\"], padding=True, truncation=True, max_length=512)\n",
        "\n",
        "# applying tokenized function on tha dataset in batches.\n",
        "tokenized_tweet_dataset = tweet_dataset.map(tokenize_function, batched=True)"
      ],
      "metadata": {
        "id": "j_jnETL0Irxc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# first 5 test instances shown.\n",
        "tweet_dataset.set_format(type='pandas')\n",
        "df = tweet_dataset['test'][:]\n",
        "df.head()"
      ],
      "metadata": {
        "id": "OJ3FpdZ3N3q7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import DistilBertForSequenceClassification, Trainer, TrainingArguments\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# loading the pre-trained weight of distilbert for sequence classification and initialize a model with two labels.\n",
        "def model_init():\n",
        "  return DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=2)"
      ],
      "metadata": {
        "id": "UIlYfYReH9Tw"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"distilbert-finetuned-tweet-eval\"\n",
        "\n",
        "# Training arguments.\n",
        "training_args = TrainingArguments(\n",
        "  output_dir=model_name, # Directory for saving outputs\n",
        "  learning_rate=9.345135299518317e-05, # Learning rate for optimization\n",
        "  seed = 13, # random seed value\n",
        "  per_device_train_batch_size=64, # Batch size for training\n",
        "  per_device_eval_batch_size=64, # Batch size for evaluation\n",
        "  num_train_epochs=3, # Number of training epochs\n",
        "  weight_decay=0.01, # Weight decay for regularization\n",
        "  # load_best_model_at_end=True,\n",
        "  evaluation_strategy=\"epoch\", # Evaluation is done at the end of each epoch\n",
        "  save_strategy = \"epoch\",\n",
        ")"
      ],
      "metadata": {
        "id": "7O-jHC_sJPKM"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Trainer Initialization using training pipeline from huggingface.\n",
        "trainer = Trainer(\n",
        "  model_init=model_init,\n",
        "  args=training_args,\n",
        "  train_dataset=tokenized_tweet_dataset['train'],\n",
        "  eval_dataset=tokenized_tweet_dataset['validation'],\n",
        "  compute_metrics=lambda p: {\"accuracy\": accuracy_score(p.label_ids,\n",
        "  np.argmax(p.predictions, axis=1))},\n",
        "  tokenizer=tokenizer\n",
        ")"
      ],
      "metadata": {
        "id": "76abKrnVOXeQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# splitting the test, train, and validation dataset.\n",
        "test_dataset = tokenized_tweet_dataset['test']\n",
        "training_dataset = tokenized_tweet_dataset['train']\n",
        "valid_dataset = tokenized_tweet_dataset['validation']"
      ],
      "metadata": {
        "id": "PWsG5twWOpLi"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Untrained state evaluation.\n",
        "eval_training = trainer.evaluate(training_dataset)\n",
        "eval_validation = trainer.evaluate(valid_dataset)\n",
        "eval_testing = trainer.evaluate(test_dataset)\n",
        "\n",
        "# printing untrained state accuracy\n",
        "print(\"Training: \", eval_training)\n",
        "print(\"Validation: \", eval_validation)\n",
        "print(\"Testing: \", eval_testing)"
      ],
      "metadata": {
        "id": "hq62aOL4OYml"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install optuna\n",
        "! pip install ray[tune]\n",
        "\n",
        "# Hyper parameter search for 10 number of trials to find the maximized accuracy\n",
        "eval = trainer.hyperparameter_search(n_trials=10, direction=\"maximize\")\n",
        "print(eval)"
      ],
      "metadata": {
        "id": "pCYZLs_7IAg8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Untrained state evaluation\n",
        "from transformers import DistilBertTokenizer, DistilBertConfig, DistilBertModel\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# loads the distilbert model\n",
        "model_path = 'distilbert-base-uncased'\n",
        "config = DistilBertConfig.from_pretrained(model_path)\n",
        "model_saved = DistilBertForSequenceClassification.from_pretrained(model_path, config=config)\n",
        "\n",
        "# first 5 test instances.\n",
        "inputs = test_dataset['text'][:5]\n",
        "\n",
        "# returns as py torch sequences using the tokenizer.\n",
        "input_ids = tokenizer(inputs, padding=True, truncation=True, return_tensors=\"pt\")[\"input_ids\"]\n",
        "\n",
        "# performs inference with a pre-trained py torch model, while making sure gradients are not calculated.\n",
        "with torch.no_grad():\n",
        "  outputs = model_saved(input_ids) # passes input_ids (input tensors) through the pre-trained model.\n",
        "\n",
        "# stores raw predictions predicted by the model.\n",
        "logits = outputs.logits\n",
        "\n",
        "# Applying softmax to obtain probabilities\n",
        "probs = F.softmax(logits, dim=-1)\n",
        "\n",
        "# Getting the predicted labels\n",
        "predicted_labels = torch.argmax(probs, dim=-1)\n",
        "\n",
        "# maps int label to string label.\n",
        "tweet_mapping = {\n",
        "    0: \"non-irony\",\n",
        "    1: \"irony\"\n",
        "}\n",
        "\n",
        "# Getting the predicted tweets string labels using the mapping\n",
        "predicted_tweets = [tweet_mapping[label.item()] for label in predicted_labels]\n",
        "\n",
        "# Tweets predicted.\n",
        "print(\"Predicted tweets:\")\n",
        "print(predicted_tweets)"
      ],
      "metadata": {
        "id": "84JonSBR3UQM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train() # training on the dataset using trainer"
      ],
      "metadata": {
        "id": "jQ_P0OSTOnSr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluating after training\n",
        "eval_validation = trainer.evaluate(valid_dataset)\n",
        "eval_testing = trainer.evaluate(test_dataset)\n",
        "\n",
        "# Printing evaluated accuracy\n",
        "print(\"Validation: \", eval_validation)\n",
        "print(\"Testing: \", eval_testing)"
      ],
      "metadata": {
        "id": "OD5bMiJMYHDl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.push_to_hub()"
      ],
      "metadata": {
        "id": "Q8a2ek6hFC7i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"iaminhridoy/distilbert-finetuned-tweet-eval\")\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\"iaminhridoy/distilbert-finetuned-tweet-eval\")\n",
        "inputs = test_dataset['text'][:5] # First 5 test instances\n",
        "\n",
        "# returns as py torch sequences using the tokenizer.\n",
        "input_ids = tokenizer(inputs, padding=True, truncation=True, return_tensors=\"pt\")[\"input_ids\"]\n",
        "\n",
        "# performs inference with a pre-trained py torch model, while making sure gradients are not calculated.\n",
        "with torch.no_grad():\n",
        "  outputs = model(input_ids) # passes input_ids (input tensors) through the pre-trained model.\n",
        "\n",
        "# stores raw predictions predicted by the model.\n",
        "logits = outputs.logits\n",
        "\n",
        "# Applying softmax to obtain probabilities\n",
        "probs = F.softmax(logits, dim=-1)\n",
        "\n",
        "# Getting the predicted labels\n",
        "predicted_labels = torch.argmax(probs, dim=-1)\n",
        "\n",
        "# maps int label to string label.\n",
        "irony_mapping = {\n",
        "    0: \"non-irony\",\n",
        "    1: \"irony\",\n",
        "}\n",
        "\n",
        "# mapping the predictions with the string labels.\n",
        "predicted_tweets = [irony_mapping[label.item()] for label in predicted_labels]\n",
        "\n",
        "# print predicted tweets\n",
        "print(\"Predicted Tweets:\")\n",
        "print(predicted_tweets)"
      ],
      "metadata": {
        "id": "B9ACAz0pYtMv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import numpy as np\n",
        "# Confusion matrix\n",
        "#____________________________________________________________________\n",
        "# predicted labels for the validation dataset\n",
        "predictions = trainer.predict(tokenized_tweet_dataset['validation'])\n",
        "\n",
        "# true labels from the validation dataset\n",
        "true_labels = tokenized_tweet_dataset['validation']['label']\n",
        "\n",
        "# converting predicted labels to numpy array\n",
        "predicted_labels = np.argmax(predictions.predictions, axis=1)\n",
        "\n",
        "# computing confusion matrix\n",
        "conf_matrix = confusion_matrix(true_labels, predicted_labels)\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# creating a dataframe from the confusion matrix\n",
        "conf_matrix_df = pd.DataFrame(conf_matrix, index=[\"True 0\", \"True 1\"], columns=[\"Predicted 0\", \"Predicted 1\"])\n",
        "\n",
        "# Print the DataFrame\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix_df)"
      ],
      "metadata": {
        "id": "y-ADKLU83bdz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Bert Model Classification-- Tweet_Eval\n"
      ],
      "metadata": {
        "id": "F5E99S2uhSRn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# importing libaries\n",
        "!pip install datasets\n",
        "from datasets import load_dataset\n",
        "from transformers import BertTokenizer\n",
        "\n",
        "# Loading dataset irony.\n",
        "tweet_dataset = load_dataset('tweet_eval', 'irony')\n",
        "\n",
        "# loading pre-trained model bert\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# Tokenize function takes a dataset as input, pads it based on max_length and truncates if above max_length.\n",
        "def tokenize_function(example):\n",
        "  return tokenizer(example[\"text\"], padding=\"max_length\", truncation=True)\n",
        "\n",
        "# applying tokenized function on tha dataset in batches.\n",
        "tokenized_tweet_dataset = tweet_dataset.map(tokenize_function, batched=True)"
      ],
      "metadata": {
        "id": "H9vfg5ljZGIm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# first 5 test instances shown.\n",
        "tweet_dataset.set_format(type='pandas')\n",
        "df = tweet_dataset['test'][:5]\n",
        "print(df)"
      ],
      "metadata": {
        "id": "_DY3SK1I6PHf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertForSequenceClassification, Trainer, TrainingArguments\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# loading the pre-trained weight of bert for sequence classification and initialize a model with two labels.\n",
        "def model_init():\n",
        "  return BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)"
      ],
      "metadata": {
        "id": "CaUhVtiMi1xl"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"bert-finetuned-tweet_eval\"\n",
        "\n",
        "# Training arguments.\n",
        "training_args = TrainingArguments(\n",
        "  output_dir=model_name, # Directory for saving outputs\n",
        "  learning_rate=7.32121081228238e-05, # Learning rate for optimization\n",
        "  seed = 16, # num of random seeds\n",
        "  per_device_train_batch_size=8, # Batch size for training\n",
        "  per_device_eval_batch_size=16, # Batch size for evaluation\n",
        "  num_train_epochs=5, # Number of training epochs\n",
        "  weight_decay=0.01, # Weight decay for regularization\n",
        "  # load_best_model_at_end=True,\n",
        "  evaluation_strategy=\"epoch\", # Evaluation is done at the end of each epoch\n",
        "  save_strategy = \"epoch\",\n",
        ")"
      ],
      "metadata": {
        "id": "2qF_Z1Rui_5h"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Trainer Initialization using training pipeline from huggingface.\n",
        "trainer = Trainer(\n",
        "  model_init=model_init,\n",
        "  args=training_args,\n",
        "  train_dataset=tokenized_tweet_dataset['train'],\n",
        "  eval_dataset=tokenized_tweet_dataset['validation'],\n",
        "  compute_metrics=lambda p: {\"accuracy\": accuracy_score(p.label_ids,\n",
        "  np.argmax(p.predictions, axis=1))},\n",
        "  tokenizer=tokenizer\n",
        ")"
      ],
      "metadata": {
        "id": "xzf0Oz8djU0N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install optuna\n",
        "! pip install ray[tune]\n",
        "\n",
        "# Hyper parameter search for 10 number of trials to find the maximized accuracy\n",
        "eval = trainer.hyperparameter_search(n_trials=10, direction=\"maximize\")\n",
        "print(eval)"
      ],
      "metadata": {
        "id": "Hbwy0-_fjiVo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# splitting the test, train, and validation dataset.\n",
        "test_dataset = tokenized_tweet_dataset['test']\n",
        "training_dataset = tokenized_tweet_dataset['train']\n",
        "valid_dataset = tokenized_tweet_dataset['validation']"
      ],
      "metadata": {
        "id": "C2btkGxIwLPk"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Untrained state evaluation.\n",
        "eval_training = trainer.evaluate(training_dataset)\n",
        "eval_validation = trainer.evaluate(valid_dataset)\n",
        "eval_testing = trainer.evaluate(test_dataset)\n",
        "\n",
        "# Printing untrained state accuracy\n",
        "print(\"Training: \", eval_training)\n",
        "print(\"Validation: \", eval_validation)\n",
        "print(\"Testing: \", eval_testing)"
      ],
      "metadata": {
        "id": "EiPmP4UbjiyY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Untrained state evaluation\n",
        "\n",
        "from transformers import BertTokenizer, BertConfig, BertModel\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# loads the bert model, config and initilizes sequence classification.\n",
        "model_path = 'bert-base-uncased'\n",
        "config = BertConfig.from_pretrained(model_path)\n",
        "model_saved = BertForSequenceClassification.from_pretrained(model_path, config=config)\n",
        "\n",
        "# first 5 test instances.\n",
        "inputs = test_dataset['text'][:5]\n",
        "\n",
        "# returns as py torch sequences using the tokenizer.\n",
        "input_ids = tokenizer(inputs, padding=True, truncation=True, return_tensors=\"pt\")[\"input_ids\"]\n",
        "\n",
        "# performs inference with a pre-trained py torch model, while making sure gradients are not calculated.\n",
        "with torch.no_grad():\n",
        "  outputs = model_saved(input_ids) # passes input_ids (input tensors) through the pre-trained model.\n",
        "\n",
        "# stores raw predictions predicted by the model.\n",
        "logits = outputs.logits\n",
        "\n",
        "# Applying softmax to obtain probabilities\n",
        "probs = F.softmax(logits, dim=-1)\n",
        "\n",
        "# Getting the predicted labels\n",
        "predicted_labels = torch.argmax(probs, dim=-1)\n",
        "\n",
        "# maps int label to string label.\n",
        "tweet_mapping = {\n",
        "    0: \"non-irony\",\n",
        "    1: \"irony\"\n",
        "}\n",
        "\n",
        "# Getting the predicted tweets string labels using the mapping\n",
        "predicted_tweets = [tweet_mapping[label.item()] for label in predicted_labels]\n",
        "\n",
        "# Printing the predicted tweets\n",
        "print(\"Predicted tweets:\")\n",
        "print(predicted_tweets)"
      ],
      "metadata": {
        "id": "9wj1R-Ao23gK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train() # training on the dataset using trainer"
      ],
      "metadata": {
        "id": "cOBSjI91xesz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluating after training\n",
        "eval_validation = trainer.evaluate(valid_dataset)\n",
        "eval_testing = trainer.evaluate(test_dataset)\n",
        "\n",
        "# Printing evaluated accuracy\n",
        "print(\"Validation: \", eval_validation)\n",
        "print(\"Testing: \", eval_testing)"
      ],
      "metadata": {
        "id": "Zw5XwefB1ELn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.push_to_hub()"
      ],
      "metadata": {
        "id": "G-8Noaz1JCd9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# saving the model.\n",
        "trainer.save_model(\"Bert-Model_FineTuned-Tweet_Eval\")"
      ],
      "metadata": {
        "id": "sdMVHl5G1Gea"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"iaminhridoy/bert-finetuned-tweet_eval\")\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\"iaminhridoy/bert-finetuned-tweet_eval\")\n",
        "# first 5 test instances.\n",
        "inputs = test_dataset['text'][:5]\n",
        "\n",
        "# returns as py torch sequences using the tokenizer.\n",
        "input_ids = tokenizer(inputs, padding=True, truncation=True, return_tensors=\"pt\")[\"input_ids\"]\n",
        "\n",
        "# performs inference with a pre-trained py torch model, while making sure gradients are not calculated.\n",
        "with torch.no_grad():\n",
        "  outputs = model(input_ids) # passes input_ids (input tensors) through the pre-trained model.\n",
        "\n",
        "# stores raw predictions predicted by the model.\n",
        "logits = outputs.logits\n",
        "\n",
        "# Applying softmax to obtain probabilities\n",
        "probs = F.softmax(logits, dim=-1)\n",
        "\n",
        "# Getting the predicted labels\n",
        "predicted_labels = torch.argmax(probs, dim=-1)\n",
        "\n",
        "# maps int label to string label.\n",
        "tweet_mapping = {\n",
        "    0: \"non-irony\",\n",
        "    1: \"irony\",\n",
        "}\n",
        "\n",
        "# Get the predicted emotion string labels using the mapping\n",
        "predicted_emotions = [tweet_mapping[label.item()] for label in predicted_labels]\n",
        "\n",
        "# Print the predicted emotions\n",
        "print(\"Predicted emotions:\")\n",
        "print(predicted_emotions)"
      ],
      "metadata": {
        "id": "nz01CA2B1sx2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import numpy as np\n",
        "\n",
        "# Confusion matrix\n",
        "#____________________________________________________________________\n",
        "\n",
        "# predicting labels for the validation dataset\n",
        "predictions = trainer.predict(tokenized_tweet_dataset['validation'])\n",
        "\n",
        "# finding true labels from the validation dataset\n",
        "true_labels = tokenized_tweet_dataset['validation']['label']\n",
        "\n",
        "# converting predicted labels to numpy array\n",
        "predicted_labels = np.argmax(predictions.predictions, axis=1)\n",
        "\n",
        "# computing confusion matrix\n",
        "conf_matrix = confusion_matrix(true_labels, predicted_labels)\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# creating a dataframe from the confusion matrix\n",
        "conf_matrix_df = pd.DataFrame(conf_matrix, index=[\"True 0\", \"True 1\"], columns=[\"Predicted 0\", \"Predicted 1\"])\n",
        "\n",
        "# Printing the DataFrame\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix_df)"
      ],
      "metadata": {
        "id": "WxNHYDW_6bhc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Albert** Model - Tweet_Eval text Classification"
      ],
      "metadata": {
        "id": "s2lx3D53lYRv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# importing datasets and tokenizer.\n",
        "!pip install datasets\n",
        "from datasets import load_dataset\n",
        "from transformers import AlbertTokenizer\n",
        "\n",
        "# loading dataset\n",
        "tweet_dataset = load_dataset('tweet_eval', 'irony')\n",
        "\n",
        "# loading pre-trained model albert\n",
        "tokenizer = AlbertTokenizer.from_pretrained('albert-base-v2')\n",
        "\n",
        "# Tokenize function takes a dataset as input, pads it based on max_length and truncates if above max_length.\n",
        "def tokenize_function(example):\n",
        "  return tokenizer(example[\"text\"], padding=True, truncation=True, max_length=160)\n",
        "\n",
        "# applying tokenized function on tha dataset in batches.\n",
        "tokenized_tweet_dataset = tweet_dataset.map(tokenize_function, batched=True)"
      ],
      "metadata": {
        "id": "EgtIkTlZlbkI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AlbertForSequenceClassification, Trainer, TrainingArguments\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# loading the pre-trained weight of distilbert for sequence classification and initialize a model with two labels.\n",
        "def model_init():\n",
        "  return AlbertForSequenceClassification.from_pretrained('albert-base-v2', num_labels=2)"
      ],
      "metadata": {
        "id": "saEXcXL6l2D9"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "albert_fine_tuned = \"AlBert-finetuned-Tweet_Eval\"\n",
        "\n",
        "# Training arguments.\n",
        "training_args = TrainingArguments(\n",
        "  output_dir=albert_fine_tuned, # Directory for saving outputs\n",
        "  learning_rate=1.5702521904670393e-05, # Learning rate for optimization\n",
        "  seed = 25, # num of random seeds\n",
        "  per_device_train_batch_size=16, # Batch size for training\n",
        "  per_device_eval_batch_size=16, # Batch size for evaluation\n",
        "  num_train_epochs=3, # Number of training epochs\n",
        "  weight_decay=0.01, # Weight decay for regularization\n",
        "  evaluation_strategy=\"epoch\", # Evaluation is done at the end of each epoch\n",
        "  save_strategy = \"epoch\",\n",
        ")"
      ],
      "metadata": {
        "id": "eNFBmpRyl5lQ"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Trainer Initialization using training pipeline from huggingface.\n",
        "trainer = Trainer(\n",
        "  model_init=model_init,\n",
        "  args=training_args,\n",
        "  train_dataset=tokenized_tweet_dataset['train'],\n",
        "  eval_dataset=tokenized_tweet_dataset['validation'],\n",
        "  compute_metrics=lambda p: {\"accuracy\": accuracy_score(p.label_ids,\n",
        "  np.argmax(p.predictions, axis=1))},\n",
        "  tokenizer=tokenizer\n",
        ")"
      ],
      "metadata": {
        "id": "p_siJsLXmARf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# splitting the test, train, and validation dataset.\n",
        "training_dataset = tokenized_tweet_dataset['train']\n",
        "validation_dataset = tokenized_tweet_dataset['validation']\n",
        "test_dataset = tokenized_tweet_dataset['test']"
      ],
      "metadata": {
        "id": "2bGRVhOMl_5M"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Untrained state evaluation.\n",
        "eval_training = trainer.evaluate(training_dataset)\n",
        "eval_validation = trainer.evaluate(validation_dataset)\n",
        "eval_test = trainer.evaluate(test_dataset)\n",
        "\n",
        "# Printing untrained state accuracy\n",
        "print(\"Training: \", eval_training)\n",
        "print(\"Validation: \", eval_validation)\n",
        "print(\"Testing: \", eval_test)"
      ],
      "metadata": {
        "id": "HN-9OvW_mHAZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Untrained state evaluation\n",
        "\n",
        "from transformers import AlbertTokenizer, AlbertConfig, AlbertModel\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# loads the Albert model, and initilizes config, sequence classification.\n",
        "model_path = 'albert-base-v2'\n",
        "config = AlbertConfig.from_pretrained(model_path)\n",
        "model_saved = AlbertForSequenceClassification.from_pretrained(model_path, config=config)\n",
        "\n",
        "# first 5 test instances.\n",
        "inputs = test_dataset['text'][:5]\n",
        "\n",
        "# returns as py torch sequences using the tokenizer.\n",
        "input_ids = tokenizer(inputs, padding=True, truncation=True, return_tensors=\"pt\")[\"input_ids\"]\n",
        "\n",
        "# performs inference with a pre-trained py torch model, while making sure gradients are not calculated.\n",
        "with torch.no_grad():\n",
        "  outputs = model_saved(input_ids) # passes input_ids (input tensors) through the pre-trained model.\n",
        "\n",
        "# stores raw predictions predicted by the model.\n",
        "logits = outputs.logits\n",
        "\n",
        "# Applying softmax to obtain probabilities\n",
        "probs = F.softmax(logits, dim=-1)\n",
        "\n",
        "# Getting the predicted labels\n",
        "predicted_labels = torch.argmax(probs, dim=-1)\n",
        "\n",
        "# maps int label to string label.\n",
        "tweet_mapping = {\n",
        "    0: \"non-irony\",\n",
        "    1: \"irony\"\n",
        "}\n",
        "\n",
        "# getting the predicted emotions string labels using the mapping\n",
        "predicted_tweets = [tweet_mapping[label.item()] for label in predicted_labels]\n",
        "\n",
        "# tweets predicted in untrained state.\n",
        "print(\"Predicted tweets:\")\n",
        "print(predicted_tweets)"
      ],
      "metadata": {
        "id": "FWFWYBmW2EHn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# installing libraries\n",
        "! pip install optuna\n",
        "! pip install ray[tune]\n",
        "# Hyper parameter search for 10 number of trials to find the maximized accuracy\n",
        "eval = trainer.hyperparameter_search(n_trials=10, direction=\"maximize\")\n",
        "print(eval)"
      ],
      "metadata": {
        "id": "iAugFS9P71OP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train() # training on the dataset using trainer"
      ],
      "metadata": {
        "id": "iLHD1E2fmODY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluating after training\n",
        "eval_training = trainer.evaluate(training_dataset)\n",
        "eval_validation = trainer.evaluate(validation_dataset)\n",
        "eval_test = trainer.evaluate(test_dataset)\n",
        "\n",
        "# Printing evaluated accuracy\n",
        "print(\"Training: \", eval_training)\n",
        "print(\"Validation: \", eval_validation)\n",
        "print(\"Testing: \", eval_test)"
      ],
      "metadata": {
        "id": "FRtFxIGbmRr6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.push_to_hub()"
      ],
      "metadata": {
        "id": "UhwCga3FPPZ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"iaminhridoy/AlBert-finetuned-Tweet_Eval\")\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\"iaminhridoy/AlBert-finetuned-Tweet_Eval\")\n",
        "\n",
        "\n",
        "# first 5 test instances.\n",
        "inputs = test_dataset['text'][:5]\n",
        "\n",
        "# returns as py torch sequences using the tokenizer.\n",
        "input_ids = tokenizer(inputs, padding=True, truncation=True, return_tensors=\"pt\")[\"input_ids\"]\n",
        "\n",
        "\n",
        "# performs inference with a pre-trained py torch model, while making sure gradients are not calculated.\n",
        "with torch.no_grad():\n",
        "  outputs = model(input_ids) # passes input_ids (input tensors) through the pre-trained model.\n",
        "\n",
        "# stores raw predictions predicted by the model.\n",
        "logits = outputs.logits\n",
        "\n",
        "# Applying softmax to obtain probabilities\n",
        "probs = F.softmax(logits, dim=-1)\n",
        "\n",
        "# Getting the predicted labels\n",
        "predicted_labels = torch.argmax(probs, dim=-1)\n",
        "\n",
        "# maps int label to string label.\n",
        "tweet_mapping = {\n",
        "    0: \"non-irony\",\n",
        "    1: \"irony\"\n",
        "}\n",
        "\n",
        "# Getting the predicted tweets string labels using the mapping\n",
        "predicted_irony = [tweet_mapping[label.item()] for label in predicted_labels]\n",
        "\n",
        "# Printing the predicted tweets\n",
        "print(\"Predicted Irony:\")\n",
        "print(predicted_irony)\n"
      ],
      "metadata": {
        "id": "a0ybKirymt2s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import numpy as np\n",
        "\n",
        "# Confusion matrix\n",
        "#____________________________________________________________________\n",
        "\n",
        "# predicting labels for the validation dataset\n",
        "predictions = trainer.predict(tokenized_tweet_dataset['validation'])\n",
        "\n",
        "# finding true labels from the validation dataset\n",
        "true_labels = tokenized_tweet_dataset['validation']['label']\n",
        "\n",
        "# converting predicted labels to numpy array\n",
        "predicted_labels = np.argmax(predictions.predictions, axis=1)\n",
        "\n",
        "# computing confusion matrix\n",
        "conf_matrix = confusion_matrix(true_labels, predicted_labels)\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# creating a dataframe from the confusion matrix\n",
        "conf_matrix_df = pd.DataFrame(conf_matrix, index=[\"True 0\", \"True 1\"], columns=[\"Predicted 0\", \"Predicted 1\"])\n",
        "\n",
        "# Printing the dataframe\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix_df)"
      ],
      "metadata": {
        "id": "djEURrRC3JrO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}